{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook overview\n",
    "1. Read in the data (function)\n",
    "    - Making sure that the data is in the correct format\n",
    "    - Function does the label mapping and conversion of labels to label ids\n",
    "\n",
    "2. Transform data into Huggingface Dataset object\n",
    "\n",
    "3. Tokenize and align labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/NLP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig, RobertaTokenizerFast, DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from evaluate import load \n",
    "from span_f1 import readNlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data files\n",
    "path_train = \"en_ewt-ud-train.iob2\"\n",
    "path_dev = \"en_ewt-ud-dev.iob2\"\n",
    "path_test = \"en_ewt-ud-test-masked.iob2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model name\n",
    "model_name = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the label to id mapping \n",
    "data_labels = readNlu(path_train) # reads in label column\n",
    "\n",
    "label_set = set()\n",
    "\n",
    "for labels in data_labels:\n",
    "    label_set.update(labels)\n",
    "\n",
    "num_labels = len(label_set)\n",
    "\n",
    "label2id = {label: id for id, label in enumerate(label_set)}\n",
    "\n",
    "id2label = {id: label for label, id in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading iob2 data (from solution for assignment 5)\n",
    "def read_iob2_file(path):\n",
    "    '''\n",
    "    This function reads iob2 files\n",
    "    \n",
    "    Parameters:\n",
    "    - path: path to read from\n",
    "\n",
    "    Returns:\n",
    "    - list with dictionaries for each sentence where the keys are 'tokens', 'ner_tags', and 'tag_ids' and \n",
    "      the values are lists that hold the tokens, ner_tags, and tag_ids.\n",
    "    '''\n",
    "\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "    current_tag_ids = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip() # removes any leading and trailing whitespaces from the line\n",
    "\n",
    "        if line:\n",
    "            if line[0] == '#': \n",
    "                continue # skip comments\n",
    "\n",
    "            # splitting at 'tab', as the data is tab separated \n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            # add the entry in the second colun (the word) to current_words\n",
    "            current_words.append(tok[1]) \n",
    "\n",
    "            # add the current tag \n",
    "            current_tags.append(tok[2]) \n",
    "\n",
    "            # add the current tag mapped to the corresponding id (int)\n",
    "            current_tag_ids.append(label2id[tok[2]]) \n",
    "        \n",
    "        else: # skip empty lines\n",
    "            if current_words: # if current_words is not empty\n",
    "\n",
    "                # add entry to dict where tokens and ner_tags are keys and the values are lists\n",
    "                data.append({\"tokens\": current_words, \"ner_tags\": current_tags, \"tag_ids\": current_tag_ids})\n",
    "\n",
    "            # start over  \n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "            current_tag_ids = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append({\"tokens\": current_words, \"ner_tags\": current_tags, \"tag_ids\": current_tag_ids})\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "train_data = read_iob2_file(path_train)\n",
    "dev_data = read_iob2_file(path_dev)\n",
    "test_data = read_iob2_file(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to huggingface format\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "dev_dataset = Dataset.from_list(dev_data)\n",
    "test_dataset = Dataset.from_list(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and align labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "    model_name, \n",
    "    use_fast = True, \n",
    "    add_prefix_space = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function \n",
    "def tokenize_and_align_labels(data):\n",
    "    '''\n",
    "    This function tokentizes the tokens and align the labels to the newly created subwords.\n",
    "    The tokens can be split into multiple subwords, which are marked with -100, so they are ignored\n",
    "    in the model *********\n",
    "\n",
    "    Parameters:\n",
    "        - data : the data we wish to tokenize and align. Must be a Huggingface dataset.\n",
    "\n",
    "    Returns: \n",
    "        - the tokenized input with aligned labels.\n",
    "    '''\n",
    "\n",
    "    # tokenize the input\n",
    "    tokenized_inputs = tokenizer(\n",
    "        data[\"tokens\"],             # tokenize the tokens (words)\n",
    "        is_split_into_words = True, # tells the tokenizer each item in the list is already a separate word/token\n",
    "        truncation = True,          # if a sentence is longer than the max_length it will be truncated / cut off \n",
    "        max_length = 128,           # a sentence can't be longer than 128\n",
    "        padding = False             # no padding to save memory\n",
    "    )\n",
    "\n",
    "    \n",
    "    # create empty list for aligned labels (to the subwords)\n",
    "    all_labels = []\n",
    "\n",
    "    # loop through each sentence\n",
    "    for batch_index, labels in enumerate(data[\"tag_ids\"]): \n",
    "        \n",
    "        # 'word_ids()' returns a list the same length as the subword-tokens,\n",
    "        # each entry telling you which 'word' or token it came from\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index = batch_index)  \n",
    "        \n",
    "        label_ids = []\n",
    "        prev_word_id = None  \n",
    "\n",
    "        # loop through the ids of the subword-tokens \n",
    "        for word_id in word_ids:\n",
    "\n",
    "            if word_id is None:\n",
    "                # e.g. special tokens or padding => ignore\n",
    "                label_ids.append(-100)\n",
    "\n",
    "            elif word_id == prev_word_id:\n",
    "                # subword token of the same word => ignore\n",
    "                label_ids.append(-100)\n",
    "            \n",
    "            else:\n",
    "                # new subword, so use the label for the original token\n",
    "                label_ids.append(labels[word_id])\n",
    "            \n",
    "            # move on to the next word\n",
    "            prev_word_id = word_id\n",
    "        \n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    # add the new algined labels to the tokenized inputs\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12543/12543 [00:00<00:00, 24330.26 examples/s]\n",
      "Map: 100%|██████████| 2001/2001 [00:00<00:00, 35771.74 examples/s]\n",
      "Map: 100%|██████████| 2077/2077 [00:00<00:00, 37582.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched = True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_dev_dataset = dev_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dev_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# defining the model and config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels = num_labels, \n",
    "    id2label = id2label, \n",
    "    label2id = label2id\n",
    ")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype = 'auto', \n",
    "    config = config\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are running the code on a Mac so we use MPS. Might need to change it depending on the machine the code is run on (ex. HPC)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"output_trainer\", \n",
    "    eval_strategy = 'epoch', \n",
    "    save_strategy = \"no\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fuction to convert prediction into labels\n",
    "def pred2label(predictions):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    logits, labels = predictions # unpack predictons into logits (probabilities) and labels\n",
    "\n",
    "    preds = np.argmax(logits, axis = -1) # choose the highest probability as the prediciton\n",
    "\n",
    "    true_labels = [] # list to hold true labels\n",
    "    pred_labels = []  # list to hold predicted labels\n",
    "\n",
    "    # convert true labels and predictions to string\n",
    "    for pred_seq, label_seq in zip(preds, labels):\n",
    "\n",
    "        true_labels.append([id2label[label] for label in label_seq if label != -100])\n",
    "        \n",
    "        pred_labels.append([id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100])\n",
    "\n",
    "    return true_labels, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"seqeval\")  # load the seqeval metric \n",
    "\n",
    "# define a function for computing metrics during training\n",
    "def compute_metrics(predictions):\n",
    "    '''\n",
    "    This function computes precision, recall, f1 and accuracy.\n",
    "\n",
    "    Parameters: \n",
    "    - predictions\n",
    "    '''\n",
    "    true_labels, pred_labels = pred2label(predictions)\n",
    "\n",
    "    results = metric.compute(predictions = pred_labels, references = true_labels)\n",
    "\n",
    "    return {\n",
    "        \"Precision\": results[\"overall_precision\"],\n",
    "        \"Recall\": results[\"overall_recall\"],\n",
    "        \"F1-score\": results[\"overall_f1\"],\n",
    "        \"Accuracy\": results[\"overall_accuracy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = tokenized_train_dataset,\n",
    "    eval_dataset = tokenized_dev_dataset,\n",
    "    compute_metrics = compute_metrics,\n",
    "    data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6272' max='6272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6272/6272 45:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.081626</td>\n",
       "      <td>0.793037</td>\n",
       "      <td>0.848861</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.985646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6272, training_loss=0.06814865691929448, metrics={'train_runtime': 2706.5149, 'train_samples_per_second': 4.634, 'train_steps_per_second': 2.317, 'total_flos': 174280056032742.0, 'train_loss': 0.06814865691929448, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output_trainer/tokenizer_config.json',\n",
       " 'output_trainer/special_tokens_map.json',\n",
       " 'output_trainer/vocab.json',\n",
       " 'output_trainer/merges.txt',\n",
       " 'output_trainer/added_tokens.json',\n",
       " 'output_trainer/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"output_trainer\")\n",
    "tokenizer.save_pretrained(\"output_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the dev set\n",
    "- For checking model performance and if formatting is correct with span_f1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicting\n",
    "dev_preds, true_labels, _ = trainer.predict(tokenized_dev_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict max logit and convert to strings\n",
    "dev_labels, dev_predictions = pred2label((dev_preds, true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_iob2_file(data, predictions = None, path = None, gold = False):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # formatting the predictions on dev set\n",
    "    format = []\n",
    "\n",
    "    # Loop through all items in dev_data\n",
    "    for i in range(len(data)):\n",
    "        if gold:\n",
    "            format.append((data[i]['tokens'], (data[i]['ner_tags'])))\n",
    "        else:\n",
    "            # Access 'tokens' in dev_data[i] and append it with the corresponding prediction\n",
    "            format.append((data[i]['tokens'], predictions[i]))\n",
    "\n",
    "    with open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "        for sentence in format:\n",
    "            words, labels = sentence\n",
    "            for idx, (word, label) in enumerate(zip(words, labels), start = 1):\n",
    "                f.write(f\"{idx}\\t{word}\\t{label}\\t-\\t-\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the iob2 file with the gold labels for dev-set\n",
    "write_iob2_file(dev_data,  path = \"dev_gold.iob2\", gold = True)\n",
    "\n",
    "# writing the iob2 file with the predicted labels for dev-set\n",
    "write_iob2_file(dev_data, predictions = dev_predictions, path = \"dev_output.iob2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    0.849896480331263\n",
      "precision: 0.8072763028515241\n",
      "slot-f1:   0.8280383257690368\n",
      "\n",
      "unlabeled\n",
      "ul_recall:    0.8933747412008282\n",
      "ul_precision: 0.8485742379547689\n",
      "ul_slot-f1:   0.870398386283409\n",
      "\n",
      "loose (partial overlap with same label)\n",
      "l_recall:    0.8944099378881988\n",
      "l_precision: 0.8534906588003933\n",
      "l_slot-f1:   0.8734713273421012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!python span_f1.py dev_gold.iob2 dev_output.iob2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/NLP/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/envs/NLP/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_preds, test_labels, _ = trainer.predict(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict max logit and convert to strings\n",
    "_, test_predictions = pred2label((test_preds, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output file for predictions on test data\n",
    "write_iob2_file(test_data, predictions = test_predictions, path = \"test_predictions.iob2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
